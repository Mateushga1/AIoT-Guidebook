{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Native PyTorch NPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch version for Neural Networks with Hope,2017\n",
    "\n",
    "Following notebook is based in the bibliography:\n",
    "\n",
    "T. Hope, Y. S. Resheff, and I. Lieder, Learning TensorFlow: A Guide to Building Deep Learning Systems. Sebastopol, CA: O'Reilly Media, 2017.\n",
    "\n",
    "**First Example**\n",
    "\n",
    "Have installed an evironment for \n",
    "|OS      | Python | Pytorch  | NPU  |\n",
    "|--------|--------|----------|------|\n",
    "| Win11  | 3.10.19   | 2.10.0+cpu | 1.28.0 |\n",
    "\n",
    "In order to check if NPU is  working, please run [NPU Test Bench] (./chapter-4/npu-TB.py)\n",
    "In order to print a \"Hello World!\", we could use the classic Python code for that.\n",
    "When Pytorch CPU+GPU is evoqued the training is handle, then NPU is evoqued for inference only.\n",
    "\n",
    "*Still have bugs on CNN example and NPU is not fully functional*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python location:\", sys.executable)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "print(\"Numpy:\", np.__version__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__)\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "# --- Intel NPU Acceleration Library ---\n",
    "try:\n",
    "    import intel_npu_acceleration_library as npu_lib\n",
    "    from intel_npu_acceleration_library.backend import MatMul\n",
    "    print(\"Intel NPU Acceleration Library: OK\")\n",
    "    npu_available = True\n",
    "except Exception as e:\n",
    "    print(\"Intel NPU Acceleration Library NOT found:\", e)\n",
    "    npu_available = False\n",
    "\n",
    "print(\"Intel NPU available?\", npu_available)\n",
    "\n",
    "# --- Simple ‚ÄúHello World‚Äù using PyTorch ---\n",
    "h = torch.tensor(list(b\"Hello\"), dtype=torch.uint8)\n",
    "w = torch.tensor(list(b\" World!\"), dtype=torch.uint8)\n",
    "hw = torch.cat([h, w])\n",
    "print(hw.numpy().tobytes().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Example**\n",
    "\n",
    "Softmax Regression is a simple classifiers using tf environment. The nomenclature used is often $w_i^j$, where $w$ is a vector; $i$ is the indice of the vector; $j$ is the class that $w$ represents. Finally, $W$ is the database of $[w^a...w^z] \\forall j \\in [a,...,z]$ avaliable classes. This softmax regression is used to train MNIST benchmark, whgihc has 9 classes as follows. To train a neural network using MNIST data base and using softmax, one may transform the image $[28x28]$ into a flaten vector of $[1 x 784]$. Thus the position of the pixels (black or white) does not matter anymore in the training. Softmax neural network has 9 outputs, one for each class, and they store the probability to the input being from such class. The most probable class must be taken. See figure below:\n",
    "\n",
    "<img src=\"../images/MNIST_dataset.png\" alt=\"MNIST Dataset\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# ===============================================\n",
    "# MNIST Training on CPU/GPU with optional NPU inference\n",
    "# ===============================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from npu_callbacks import AccuracyPlotCallback, count_neurons_and_synapses\n",
    "import numpy as np\n",
    "\n",
    "# ================= NPU Detection ===================\n",
    "try:\n",
    "    import intel_npu_acceleration_library.backend as npu_backend\n",
    "    npu_available = True\n",
    "    print(\"Intel NPU detected for inference acceleration.\")\n",
    "except ImportError:\n",
    "    npu_available = False\n",
    "    print(\"Intel NPU not available. Running CPU/GPU only.\")\n",
    "\n",
    "# ================= Dataset ========================\n",
    "transform = transforms.ToTensor()\n",
    "train_ds = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "# ================= Model ==========================\n",
    "class MNISTLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x, use_npu=False):\n",
    "        x = self.flatten(x)\n",
    "        if use_npu and npu_available:\n",
    "            # Offload linear matmul to NPU\n",
    "            X = x.detach().cpu().numpy().astype(np.float16)\n",
    "            W = self.fc.weight.detach().cpu().numpy().astype(np.float16)\n",
    "            b = self.fc.bias.detach().cpu().numpy().astype(np.float16)\n",
    "            mm = npu_backend.MatMul(W.shape[1], W.shape[0], X.shape[0])\n",
    "            y = mm.run(X, W) + b\n",
    "            return torch.tensor(y, dtype=torch.float32)\n",
    "        else:\n",
    "            return self.fc(x)\n",
    "\n",
    "model = MNISTLinear()\n",
    "\n",
    "# Use CPU or GPU for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# ================= Optimizer & Loss =================\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# ================= Callback =================\n",
    "callback = AccuracyPlotCallback()\n",
    "\n",
    "# ================= Training Loop ===================\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    train_correct, train_total = 0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)  # regular PyTorch linear (autograd works)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        train_total += xb.size(0)\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # --- Validation (with optional NPU acceleration) ---\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            # Use NPU for inference if available\n",
    "            logits = model(xb, use_npu=True)\n",
    "            val_correct += (logits.argmax(1) == yb).sum().item()\n",
    "            val_total += xb.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    # --- Callback ---\n",
    "    callback.on_epoch_end(epoch, train_acc, val_acc)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ================= Final Evaluation =================\n",
    "print(\"\\nFinal evaluation (NPU inference if available):\")\n",
    "model.eval()\n",
    "val_correct, val_total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb, use_npu=True)\n",
    "        val_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        val_total += xb.size(0)\n",
    "final_acc = val_correct / val_total\n",
    "print(\"Test Accuracy:\", final_acc)\n",
    "\n",
    "# ================= Count neurons & synapses =========\n",
    "count_neurons_and_synapses(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning and the Train/Test Scheme\n",
    "\n",
    "Supervised learning generally refers to the task of learning a function from data objects to labels associated with them, based on a set of examples where the correct labels are already known. This is usually subdivided into the case where labels are continuous (regression) or discrete (classification). \n",
    "\n",
    "The purpose of training supervised learning models is almost always to apply them later to new examples with unknown labels called inference phase, in order to obtain predicted labels for them. In the MNIST case discussed in this section, the purpose of training the model would probably be to apply it on new handwritten digit images and automatically find out what digits they represent.\n",
    "\n",
    "As a result, we are interested in the extent to which our model will label new examples correctly. This is reflected in the way we evaluate the accuracy of the model. We first partition the labeled dataset into train and test partitions. During model training, we use only the train partition, and during validation we test the accuracy only on the test partition. This scheme is generally known as a train/test validation.\n",
    "\n",
    "The actual training of the model, in the stochastic gradient descent (SGD) approach, consists of taking many steps in ‚Äúthe right direction.‚Äù The SGD optimizer used in this example is Adam. The cost function used is a cross entropy pre-defined fuction. The metric is the model accuracy, which is plotted during training and validation. \n",
    "\n",
    "In this example,we learn what is a epoch and a batch_size. To correclty define them, we have found.\n",
    "An epoch is one full pass over the entire training dataset. The number of epochs affects:\n",
    "\n",
    "‚úÖ Training Time:\n",
    "\n",
    "- More epochs = longer training time.\n",
    "- Too many epochs can lead to overfitting, where the model memorizes the training data instead of generalizing.\n",
    "\n",
    "‚úÖ Model Performance:\n",
    "\n",
    "- 5 epochs is often enough for simple datasets like MNIST because the softmax classifier is relatively simple.\n",
    "- More complex models may require more epochs to learn complex patterns.\n",
    "- If accuracy is low after 5 epochs, increasing the number of epochs (e.g., 10 or 20) can improve performance.\n",
    "\n",
    "üöÄ How to choose the right number of epochs?\n",
    "Use early stopping to stop training when the validation accuracy stops improving. Example:\n",
    "```python\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stopping])\n",
    "```\n",
    "\n",
    "The batch size determines how many training samples are processed before updating the model's weights.\n",
    "\n",
    "‚úÖ Effect on Memory:\n",
    "\n",
    "- A larger batch size (e.g., 128, 256) requires more GPU/CPU memory but speeds up training.\n",
    "- A smaller batch size (e.g., 16 or 32) takes longer but uses less memory.\n",
    "\n",
    "‚úÖ Effect on Model Performance:\n",
    "\n",
    "- Smaller batch sizes (e.g., 32, 64) ‚Üí More stable updates, better generalization.\n",
    "- Larger batch sizes (e.g., 128, 256) ‚Üí Faster training but may generalize worse.\n",
    "\n",
    "üöÄ How to choose the right batch size?\n",
    "\n",
    "-  32 or 64 is a good starting point for most problems. <- Golden Number from Rule of Thumb\n",
    "- If training is slow, increase batch size (but check GPU memory usage).\n",
    "- If results fluctuate a lot, try smaller batch sizes (e.g., 16).\n",
    "\n",
    "The result is a neural network model described as:\n",
    "- Input Layer: 784 neurons (flattened 28√ó28 images)\n",
    "- Dense Output Layer: 10 neurons (softmax activation for classification)\n",
    "- This is a fully connected layer, every input neuron connects to every neuron in the next layer:\n",
    "\n",
    "$Synapses=Input Neurons√óOutput Neurons+Bias Terms$\n",
    "\n",
    "$Synapses=(784√ó10)+10=7850$\n",
    "\n",
    "[ Input Layer ] ‚Üí  [ Dense Layer (784 neurons) ] ‚Üí [ Output Layer (10 neurons, softmax) ]\n",
    "\n",
    "<img src=\"../images/model_architecture.png\" alt=\"NN model\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Linear Graph for a Neural Network\n",
    "\n",
    "We have some target variable y, which we want to explain using some feature vector\n",
    "x. To do so, we first choose a model that relates the two. Our training data points will\n",
    "be used for ‚Äútuning‚Äù the model so that it best captures the desired relation. In the fol‚Äê\n",
    "lowing chapters we focus on deep neural network models, but for now we will settle\n",
    "for a simple regression problem.\n",
    "Let‚Äôs start by describing our regression model:\n",
    "\n",
    "$f(x_i) = w^Tx_i +b$\n",
    "\n",
    "$y_i = f(x_i) +\\epsilon_i$\n",
    "\n",
    "$f(x_i)$ is assumed to be a linear combination of some input data xi, with a set of\n",
    "weights $w$ and an intercept $b$. Our target output $y_i$ is a noisy version of $f(x_i)$ after being\n",
    "summed with Gaussian noise $\\epsilon_i$ (where $i$ denotes a given sample).\n",
    "\n",
    "# What is a Loss Function ?\n",
    "It a good measure with which we can evaluate the model‚Äôs performance.To capture the discrepancy between our model‚Äôs predictions and the observed targets, we need a measure reflecting ‚Äúdistance.‚Äù This distance is often referred to as an objective or a loss function, and we optimize the model by finding the set of parameters (weights and bias in this case) that minimize it.\n",
    "\n",
    "Perhaps the most commonly used loss is the MSE (mean squared error), where for all\n",
    "samples we average the squared distances between the real target and what our model\n",
    "predicts across samples:\n",
    "\n",
    "$L(y, \\hat{y}) = \\frac {1}{n} \\sum^{n}_{i=1}\\left( y_i - \\hat{y}_i\\right)^2$\n",
    "\n",
    "Which turns in Python to:\n",
    "```python\n",
    "loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "```\n",
    "\n",
    "Another very common loss, especially for categorical data, is the cross entropy, which\n",
    "we used in the softmax classifier in the previous chapter. The cross entropy is given\n",
    "by\n",
    "\n",
    "$H(p,q) = - \\sum_x p(x)\\log{q(x)}$\n",
    "\n",
    "and for classification with a single correct label (as is the case in an overwhelming\n",
    "majority of the cases) reduces to the negative log of the probability placed by the classifier on the correct label.\n",
    "\n",
    "Which turns in Python to:\n",
    "```python\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n",
    "loss = tf.reduce_mean(loss)\n",
    "```\n",
    "\n",
    "Cross entropy is a measure of similarity between two distributions. Since the classifi‚Äê\n",
    "cation models used in deep learning typically output probabilities for each class, we\n",
    "can compare the true class (distribution $p$) with the probabilities of each class given\n",
    "by the model (distribution $q$). The more similar the two distributions, the smaller our\n",
    "cross entropy will be.\n",
    "\n",
    "# Gradient Descent Optimizer: how to train neural networks?\n",
    "\n",
    "While in some cases it is possible to find the global minimum analytically (when it exists), in\n",
    "the great majority of cases we will have to use an optimization algorithm. Optimizers\n",
    "update the set of weights iteratively in a way that decreases the loss over time.\n",
    "\n",
    "*Lemma:*\n",
    "\n",
    "So if $\\hat{w}_1 = \\hat{w}_0-\\gamma \\nabla F(\\hat{w}_0)$ where $\\nabla F(\\hat{w}_0)$ is the gradient of $F$ evaluated at $\\hat{w}_0$, then for a\n",
    "small enough $\\gamma$:\n",
    "\n",
    "$F(\\hat{w}_0) \\geq F(\\hat{w}_1)$\n",
    "\n",
    "While convergence to the global minimum is guaranteed for convex functions, for nonconvex problems\n",
    "(which are essentially all problems in the world of deep learning) they can get stuck\n",
    "in local minima. In practice, this is often good enough, as is evidenced by the huge\n",
    "success of the field of deep learning.\n",
    "\n",
    "A more popular technique is the *stochastic gradient descent (SGD)*, where instead of\n",
    "feeding the entire dataset to the algorithm for the computation of each step, a subset\n",
    "of the data is sampled sequentially. The number of samples ranges from one sample at\n",
    "a time to a few hundred, but the most common sizes are between around 50 to\n",
    "around 500 (usually referred to as mini-batches).\n",
    "\n",
    "Using smaller batches usually works faster, and the smaller the size of the batch, the\n",
    "faster are the calculations. However, there is a trade-off in that small samples lead to\n",
    "lower hardware utilization and tend to have high variance, causing large fluctuations\n",
    "to the objective function. Nevertheless, it turns out that some fluctuations are benefi‚Äê\n",
    "cial since they enable the set of parameters to jump to new and potentially better local\n",
    "minima. Using a relatively smaller batch size is therefore effective in that regard, and\n",
    "is currently overall the preferred approach.\n",
    "\n",
    "An important parameter to set is the algorithm‚Äôs learning rate, determining how\n",
    "aggressive each update iteration will be (or in other words, how large the step will be\n",
    "in the direction of the negative gradient). We want the decrease in the loss to be fast\n",
    "enough on the one hand, but on the other hand not large enough so that we over-\n",
    "shoot the target and end up at a point with a higher value of the loss function.\n",
    "\n",
    "**Fourth Example: linear regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# ===============================\n",
    "# Matplotlib config\n",
    "# ===============================\n",
    "matplotlib.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'text.usetex': False\n",
    "})\n",
    "\n",
    "# ===============================\n",
    "# Detect Intel NPU Backend\n",
    "# ===============================\n",
    "try:\n",
    "    import intel_npu_acceleration_library.backend as npu_backend\n",
    "    NPU_AVAILABLE = True\n",
    "    print(\"Intel NPU backend detected (inference only).\")\n",
    "except ImportError:\n",
    "    NPU_AVAILABLE = False\n",
    "    print(\"Intel NPU not available.\")\n",
    "\n",
    "# ===============================\n",
    "# Device (CPU/GPU for training)\n",
    "# ===============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===============================\n",
    "# Model Definition\n",
    "# ===============================\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x, use_npu=False):\n",
    "        if use_npu and NPU_AVAILABLE:\n",
    "            # NPU inference path (NO autograd here)\n",
    "            X = x.detach().cpu().numpy().astype(np.float16)\n",
    "            W = self.linear.weight.detach().cpu().numpy().astype(np.float16)\n",
    "            b = self.linear.bias.detach().cpu().numpy().astype(np.float16)\n",
    "\n",
    "            batch = X.shape[0]\n",
    "            in_features = W.shape[1]\n",
    "            out_features = W.shape[0]\n",
    "\n",
    "            mm = npu_backend.MatMul(in_features, out_features, batch)\n",
    "            y = mm.run(X, W.T)\n",
    "            y += b\n",
    "\n",
    "            return torch.tensor(y, dtype=torch.float32, device=x.device)\n",
    "        else:\n",
    "            return self.linear(x)\n",
    "\n",
    "# Instantiate model\n",
    "model = SimpleLinearModel().to(device)\n",
    "\n",
    "# ===============================\n",
    "# Dataset (same as TF example)\n",
    "# ===============================\n",
    "x_train = torch.tensor([\n",
    "    [1.,2.,3.],\n",
    "    [4.,5.,6.],\n",
    "    [7.,8.,9.],\n",
    "    [2.,3.,4.]\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "y_true = torch.tensor([\n",
    "    [4.],\n",
    "    [10.],\n",
    "    [16.],\n",
    "    [6.]\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "# ===============================\n",
    "# Loss & Accuracy\n",
    "# ===============================\n",
    "def compute_loss(y_true, y_pred):\n",
    "    return torch.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    abs_percentage_error = torch.abs((y_pred - y_true) / y_true)\n",
    "    mape = torch.mean(abs_percentage_error)\n",
    "    accuracy = 1 - mape\n",
    "    return torch.clamp(accuracy, 0, 1)\n",
    "\n",
    "# ===============================\n",
    "# Optimizer\n",
    "# ===============================\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 300\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# ===============================\n",
    "# Training Loop (CPU/GPU)\n",
    "# ===============================\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = model(x_train, use_npu=False)  # PURE PyTorch training\n",
    "    loss = compute_loss(y_true, y_pred)\n",
    "    accuracy = compute_accuracy(y_true, y_pred)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        loss_values.append(loss.item())\n",
    "        accuracy_values.append(accuracy.item())\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, Accuracy: {accuracy.item():.6f}\")\n",
    "\n",
    "# ===============================\n",
    "# Plot Loss\n",
    "# ===============================\n",
    "plt.figure()\n",
    "plt.plot(range(0, epochs, 50), loss_values, marker='o')\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ===============================\n",
    "# Plot Accuracy\n",
    "# ===============================\n",
    "plt.figure()\n",
    "plt.plot(range(0, epochs, 50), accuracy_values, marker='*')\n",
    "plt.title(\"Accuracy vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ===============================\n",
    "# Final Evaluation (Optional NPU)\n",
    "# ===============================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_final = model(x_train, use_npu=True)  # NPU inference path\n",
    "\n",
    "final_loss = compute_loss(y_true, y_pred_final)\n",
    "final_accuracy = compute_accuracy(y_true, y_pred_final)\n",
    "\n",
    "print(f\"\\nFinal Loss: {final_loss.item():.6f}\")\n",
    "print(f\"Final Accuracy: {final_accuracy.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fifth Example: logistic regression**\n",
    "\n",
    "Here, the linear component $f(x_i) = w^Tx_i +b$ is the input of a nonlinear function called the logistic\n",
    "function described as \n",
    "\n",
    "$P_r\\left(y_i=1|x_i\\right) = \\frac{1}{1+ e^{wx_i +b}}$\n",
    "\n",
    "We then regard these values as probabilities from which binary yes/1 or no/0 outcomes are generated. This is the nondeterministic (noisy) part of the model.\n",
    "The logistic function is more general, and can be used with a different set of parameters for the steepness of the curve and its maximum value. This special case of a logistic function we are using is also referred to as a sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# ===============================\n",
    "# Matplotlib config\n",
    "# ===============================\n",
    "matplotlib.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'text.usetex': False  # safer unless LaTeX fully installed\n",
    "})\n",
    "\n",
    "# ===============================\n",
    "# Detect Intel NPU backend\n",
    "# ===============================\n",
    "try:\n",
    "    import intel_npu_acceleration_library.backend as npu_backend\n",
    "    NPU_AVAILABLE = True\n",
    "    print(\"Intel NPU backend detected (inference only).\")\n",
    "except ImportError:\n",
    "    NPU_AVAILABLE = False\n",
    "    print(\"Intel NPU not available.\")\n",
    "\n",
    "# ===============================\n",
    "# Device for training\n",
    "# ===============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===============================\n",
    "# Model Definition\n",
    "# ===============================\n",
    "class SimpleSigmoidModel(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, use_npu=False):\n",
    "        if use_npu and NPU_AVAILABLE:\n",
    "            # NPU inference path (detach, no gradient)\n",
    "            X = x.detach().cpu().numpy().astype(np.float16)\n",
    "            W = self.linear.weight.detach().cpu().numpy().astype(np.float16)\n",
    "            b = self.linear.bias.detach().cpu().numpy().astype(np.float16)\n",
    "\n",
    "            batch = X.shape[0]\n",
    "            in_features = W.shape[1]\n",
    "            out_features = W.shape[0]\n",
    "\n",
    "            mm = npu_backend.MatMul(in_features, out_features, batch)\n",
    "            y = mm.run(X, W.T)\n",
    "            y += b\n",
    "\n",
    "            return torch.sigmoid(torch.tensor(y, dtype=torch.float32, device=x.device))\n",
    "        else:\n",
    "            logits = self.linear(x)\n",
    "            return torch.sigmoid(logits)\n",
    "\n",
    "# Instantiate model\n",
    "model = SimpleSigmoidModel().to(device)\n",
    "\n",
    "# ===============================\n",
    "# Dataset\n",
    "# ===============================\n",
    "x_train = torch.tensor([[1.,2.,3.],\n",
    "                        [4.,5.,6.]], dtype=torch.float32).to(device)\n",
    "y_true = torch.tensor([[0.7],\n",
    "                       [0.9]], dtype=torch.float32).to(device)\n",
    "\n",
    "# Optional noise for training\n",
    "noise = torch.tensor(np.random.randn(2,1)*0.1, dtype=torch.float32).to(device)\n",
    "\n",
    "# ===============================\n",
    "# Loss & Accuracy\n",
    "# ===============================\n",
    "bce_loss = nn.BCELoss()  # Binary cross-entropy\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    return bce_loss(y_pred, y_true)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    abs_percentage_error = torch.abs((y_pred - y_true) / y_true)\n",
    "    mape = torch.mean(abs_percentage_error)\n",
    "    accuracy = 1 - mape\n",
    "    return torch.clamp(accuracy, 0, 1)\n",
    "\n",
    "# ===============================\n",
    "# Optimizer\n",
    "# ===============================\n",
    "learning_rate = 0.002\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 400\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# ===============================\n",
    "# Training Loop\n",
    "# ===============================\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train) + noise  # keep noise during training\n",
    "    loss = compute_loss(y_true, y_pred)\n",
    "    accuracy = compute_accuracy(y_true, y_pred)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        loss_values.append(loss.item())\n",
    "        accuracy_values.append(accuracy.item())\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, Accuracy: {accuracy.item():.6f}\")\n",
    "\n",
    "# ===============================\n",
    "# Plot Loss\n",
    "# ===============================\n",
    "plt.figure()\n",
    "plt.plot(range(0, epochs, 20), loss_values, marker='o')\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ===============================\n",
    "# Plot Accuracy\n",
    "# ===============================\n",
    "plt.figure()\n",
    "plt.plot(range(0, epochs, 20), accuracy_values, marker='*')\n",
    "plt.title(\"Accuracy vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ===============================\n",
    "# Final Evaluation (Optional NPU)\n",
    "# ===============================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_final = model(x_train, use_npu=True)\n",
    "final_loss = compute_loss(y_true, y_pred_final)\n",
    "final_accuracy = compute_accuracy(y_true, y_pred_final)\n",
    "\n",
    "print(f\"\\nFinal Loss: {final_loss.item():.6f}\")\n",
    "print(f\"Final Accuracy: {final_accuracy.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Convolutional Neural Networks ?\n",
    " (...)\n",
    " \n",
    "**Sixth Example MNIST Take II using CNNs**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from npu_callbacks import NpuLinear, AccuracyPlotCallback, count_neurons_and_synapses\n",
    "\n",
    "# ===============================\n",
    "# Device\n",
    "# ===============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===============================\n",
    "# Define CNN Model (PyTorch)\n",
    "# ===============================\n",
    "class MNISTNpuCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)  # padding='same'\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = NpuLinear(64 * 7 * 7, 1024)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = NpuLinear(1024, 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, use_npu=False):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        if use_npu:\n",
    "            # Optional NPU inference (no gradient)\n",
    "            if torch.is_grad_enabled():\n",
    "                with torch.no_grad():\n",
    "                    return self.softmax(x)\n",
    "            else:\n",
    "                return self.softmax(x)\n",
    "        else:\n",
    "            return self.softmax(x)\n",
    "\n",
    "# Instantiate model\n",
    "model = MNISTNpuCNN().to(device)\n",
    "\n",
    "# ===============================\n",
    "# Dataset\n",
    "# ===============================\n",
    "transform = transforms.ToTensor()\n",
    "train_ds = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds  = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "# Convert labels to one-hot\n",
    "def one_hot(y, num_classes=10):\n",
    "    return torch.nn.functional.one_hot(y, num_classes=num_classes).float()\n",
    "\n",
    "# ===============================\n",
    "# Loss and Optimizer\n",
    "# ===============================\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ===============================\n",
    "# Callback\n",
    "# ===============================\n",
    "callback = AccuracyPlotCallback()\n",
    "\n",
    "# ===============================\n",
    "# Training Loop\n",
    "# ===============================\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_correct, train_total = 0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        train_total += xb.size(0)\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb, use_npu=True)  # NPU inference\n",
    "            val_correct += (logits.argmax(1) == yb).sum().item()\n",
    "            val_total += xb.size(0)\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    callback.on_epoch_end(epoch, train_acc, val_acc)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# Final Evaluation\n",
    "# ===============================\n",
    "count_neurons_and_synapses(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10\n",
    "CIFAR10 is another dataset with a long history in computer vision and machine\n",
    "learning. Like MNIST, it is a common benchmark that various methods are tested\n",
    "against. CIFAR10 is a set of 60,000 color images of size 32√ó32 pixels, each belonging\n",
    "to one of ten categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship,\n",
    "and truck.\n",
    "\n",
    "State-of-the-art deep learning methods for this dataset are as good as humans at classifying these images. In this section we start off with much simpler methods that will\n",
    "run relatively quickly. Then, we discuss briefly what the gap is between these and the\n",
    "state of the art.\n",
    "\n",
    "Proposed neural network model consists of three blocks of convolutional layers, followed by the fully connected and output layers we have already seen a few times before. Each block of convolutional layers contains three consecutive convolutional layers, followed by a single pooling and dropout. This model is still compact\n",
    "and fast, and achieves approximately 83% accuracy after ~15 epochs. However, there is some overfitting as this accuracy is not found during testing phase.\n",
    "\n",
    "**$7^{th}$ Example CIFAR10**\n",
    "\n",
    "Please restart the Jupyter notebook to clean the used memory and run only this example after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Train Acc: 0.1174 | Val Acc: 0.1288\n",
      "\n",
      "--- Model Summary (Neurons and Synapses) ---\n",
      "fc1 | Linear | Neurons: 500, Synapses: 40500\n",
      "fc2 | Linear | Neurons: 10, Synapses: 5010\n",
      "Total neurons: 510, Total synapses: 45510\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from npu_callbacks import NpuLinear, AccuracyPlotCallback, count_neurons_and_synapses\n",
    "\n",
    "# ===============================\n",
    "# Device\n",
    "# ===============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===============================\n",
    "# Data Preprocessing (CIFAR-10)\n",
    "# ===============================\n",
    "# Training transformations (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Testing transformations\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_ds = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "test_ds  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "# ===============================\n",
    "# CIFAR-10 CNN Model\n",
    "# ===============================\n",
    "class CIFARNpuCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutions\n",
    "        self.conv1 = nn.Conv2d(3, 30, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(30, 50, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(50, 80, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(8, 8)  # big pooling\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Fully connected layers with NPU support\n",
    "        self.fc1 = NpuLinear(80 * 1 * 1, 500)  # 8x8 pooling -> 1x1 feature map\n",
    "        self.dropout = nn.Dropout(0.8)\n",
    "        self.fc2 = NpuLinear(500, 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, use_npu=False):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if use_npu:\n",
    "            # Optional NPU inference\n",
    "            if torch.is_grad_enabled():\n",
    "                with torch.no_grad():\n",
    "                    return self.softmax(x)\n",
    "            else:\n",
    "                return self.softmax(x)\n",
    "        else:\n",
    "            return self.softmax(x)\n",
    "\n",
    "# Instantiate model\n",
    "model = CIFARNpuCNN().to(device)\n",
    "\n",
    "# ===============================\n",
    "# Loss and Optimizer\n",
    "# ===============================\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# ===============================\n",
    "# Callback\n",
    "# ===============================\n",
    "callback = AccuracyPlotCallback()\n",
    "\n",
    "# ===============================\n",
    "# Training Loop\n",
    "# ===============================\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_correct, train_total = 0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_correct += (logits.argmax(1) == yb).sum().item()\n",
    "        train_total += xb.size(0)\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb, use_npu=True)  # NPU inference\n",
    "            val_correct += (logits.argmax(1) == yb).sum().item()\n",
    "            val_total += xb.size(0)\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    callback.on_epoch_end(epoch, train_acc, val_acc)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# Final Evaluation\n",
    "# ===============================\n",
    "count_neurons_and_synapses(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "It is powerful class of deep learning algorithms particularly useful and popular in natural language processing. Besides, RNN is an immensely important and useful type of neural network to process sequential structures. The type of data with strong sequential structure is natural language. That's why RNN is often employed in a supervised text classification\n",
    "problem with word-embedding training.\n",
    "\n",
    "The basic idea behind RNN models is that each new element in the sequence contributes some new information, which updates\n",
    "the current state of the model. A fundamental mathematical construct in statistics and probability, which is often\n",
    "used as a building block for modeling sequential patterns via machine learning is the\n",
    "Markov chain model. RNN applies some form of ‚Äúloop‚Äù to deal with such sequency of information. This is very related to the Markov chain models discussed previously and their\n",
    "hidden Markov model (HMM) extensions, which are not discussed here.\n",
    "\n",
    "The update step for our simple vanilla RNN is\n",
    "\n",
    "$h_t = tanh(W_x x_t + W_h h_{t-1} + b)$\n",
    "\n",
    "where $W_h$, $W_x$, and $b$ are weight and bias variables we learn, $tanh(¬∑)$ is the hyperbolic\n",
    "tangent function.\n",
    "\n",
    "While the structure of natural images is\n",
    "well suited for CNN models, it is revealing to look at the structure of images from\n",
    "different angles. In a trend in cutting-edge deep learning research, advanced models\n",
    "attempt to exploit various kinds of sequential structures in images, trying to capture\n",
    "in some sense the ‚Äúgenerative process‚Äù that created each image. Intuitively, this all\n",
    "comes down to the notion that nearby areas in images are somehow related, and trying to model this structure. We assume that the last state vector has ‚Äúaccumulated‚Äù information representing the entire sequence.\n",
    "\n",
    "Following example builds a vanilla RNN example. The model we defined is composed of two main layers:\n",
    "1. **VanillaRNNLayer**  \n",
    "   - A custom layer that processes the input sequence over 28 time steps.\n",
    "   - For each time step, it updates a hidden state of size 128 using the recurrence:\n",
    "    \n",
    "    $h_t = tanh(W_x x_t + W_h h_{t-1} + b)$\n",
    "\n",
    "    where:\n",
    "    - $W_h$ (hidden-to-hidden weights) has a shape of \\([128, 128]\\).\n",
    "    - $W_x$ (input-to-hidden weights) maps the input vector (of size 28) to a hidden state vector of size **128**.\n",
    "    - $b$ is the bias term.\n",
    "\n",
    "   - This layer encapsulates the recurrent processing logic using the parameters:\n",
    "     - `element_size` (input dimension per time step)\n",
    "     - `time_steps` (length of the sequence)\n",
    "     - `hidden_layer_size` (size of the hidden state)\n",
    "\n",
    "2. **Dense Layer**  \n",
    "   - A fully connected layer that takes the final hidden state (size 128) as input.\n",
    "   - It produces **num_classes = 10** logits for classification.\n",
    "\n",
    "\n",
    "\n",
    "The **VanillaRNNLayer** is designed with a hidden state of size **128** (`hidden_layer_size = 128`). This means that at every time step, the hidden state vector \\( h_t \\) has **128 values**. Each value represents a neuron in the recurrent layer. Because the hidden state $h_t$ is of size **128**, this confirms that the recurrent layer effectively contains **128 neurons**.\n",
    "\n",
    "Thus, the recurrent layer in your model indeed has **128 neurons**. This layer is followed by a fully connected layer of **10 neurons**, which produces the **10** output logits required for a MNIST classification.\n",
    "\n",
    "**$8^{th}$ Example MNIST classification using a vanilla RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from callbackPlots import AccuracyPlotCallback\n",
    "\n",
    "# Parameters\n",
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize and reshape dataset for RNNs\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, time_steps, element_size)  \n",
    "x_test = x_test.reshape(-1, time_steps, element_size)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Create dataset batches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "\n",
    "# Define a custom vanilla RNN model using subclassing\n",
    "class VanillaRNNLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_layer_size, **kwargs):\n",
    "        super(VanillaRNNLayer, self).__init__(**kwargs)\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        element_size = input_shape[-1]  # Get element size dynamically\n",
    "\n",
    "        # Define Weights and Biases\n",
    "        self.Wx = self.add_weight(name=\"Wx\", shape=(element_size, self.hidden_layer_size),\n",
    "                                  initializer='random_normal', trainable=True)\n",
    "        self.Wh = self.add_weight(name=\"Wh\", shape=(self.hidden_layer_size, self.hidden_layer_size),\n",
    "                                  initializer='random_normal', trainable=True)\n",
    "        self.b_rnn = self.add_weight(name=\"b_rnn\", shape=(self.hidden_layer_size,),\n",
    "                                     initializer='zeros', trainable=True)\n",
    "        super(VanillaRNNLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        time_steps = tf.shape(inputs)[1]  # Dynamically get time steps\n",
    "\n",
    "        hidden_state = tf.zeros([batch_size, self.hidden_layer_size])\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            x_t = inputs[:, t, :]\n",
    "            hidden_state = tf.tanh(\n",
    "                tf.matmul(hidden_state, self.Wh) +\n",
    "                tf.matmul(x_t, self.Wx) +\n",
    "                self.b_rnn\n",
    "            )\n",
    "\n",
    "        return hidden_state\n",
    "\n",
    "class VanillaRNN(tf.keras.Model):\n",
    "    def __init__(self, hidden_layer_size, num_classes, **kwargs):\n",
    "        super(VanillaRNN, self).__init__(**kwargs)\n",
    "        self.rnn_layer = VanillaRNNLayer(hidden_layer_size)\n",
    "        self.dense = tf.keras.layers.Dense(num_classes)  # No activation to keep logits\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.rnn_layer(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits  # Return unnormalized scores (logits)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "\n",
    "vanilla_rnn_model = VanillaRNN(hidden_layer_size=hidden_layer_size, num_classes=num_classes)\n",
    "\n",
    "# Optionally, build the model to see the summary:\n",
    "vanilla_rnn_model.build(input_shape=(None, time_steps, element_size))\n",
    "\n",
    "# Create the callback instance\n",
    "plot_callback = AccuracyPlotCallback()\n",
    "\n",
    "# Debugging: Print if the callback is created correctly\n",
    "print(f\"Callback created: {plot_callback}\")\n",
    "\n",
    "# Compile & Train\n",
    "vanilla_rnn_model.compile(optimizer='adam',\n",
    "                          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "vanilla_rnn_model.fit(train_dataset, epochs=10, validation_data=test_dataset, callbacks=[plot_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = vanilla_rnn_model.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "vanilla_rnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$9^{th}$ Example MNIST classification Simple RNN from Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from callbackPlots import AccuracyPlotCallback\n",
    "from callbackPlots import count_neurons_and_synapses\n",
    "\n",
    "# Define some parameters\n",
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize images to [0,1] range\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Reshape the dataset for RNNs\n",
    "x_train = x_train.reshape(-1, time_steps, element_size)  # (batch, 28, 28)\n",
    "x_test = x_test.reshape(-1, time_steps, element_size)\n",
    "\n",
    "\n",
    "# Convert labels to categorical (if needed)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Create TensorFlow dataset for batching\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.SimpleRNN(hidden_layer_size, activation=\"tanh\", input_shape=(time_steps, element_size)),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")  # Fully connected output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],)  # Explicitly add metrics\n",
    "\n",
    "# Create the callback instance\n",
    "plot_callback = AccuracyPlotCallback()\n",
    "\n",
    "# Debugging: Print if the callback is created correctly\n",
    "print(f\"Callback created: {plot_callback}\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset,callbacks=[plot_callback])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
    "# Save the model in Keras format (.keras)\n",
    "model_filename = f\"model_Accu{test_acc:.4f}.keras\"\n",
    "model.save(model_filename)\n",
    "\n",
    "# Model summary\n",
    "model.summary() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-npu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
